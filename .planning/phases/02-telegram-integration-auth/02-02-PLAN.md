---
phase: 02-telegram-integration-auth
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/ai/claude.ts
  - src/telegram/handlers/message.ts
  - src/index.ts
autonomous: false

must_haves:
  truths:
    - "User can send a text message to Rachel and receive an AI-generated response"
    - "Rachel shows typing indicator while Claude generates a response"
    - "Rachel keeps running after errors in individual messages"
    - "Bot process stays alive via long polling (no setInterval keepalive)"
    - "Bot shuts down cleanly on SIGTERM and SIGINT"
  artifacts:
    - path: "src/ai/claude.ts"
      provides: "Anthropic SDK client and response generation"
      exports: ["generateResponse"]
    - path: "src/telegram/handlers/message.ts"
      provides: "Text message handler connecting Telegram to Claude"
      exports: ["handleMessage"]
    - path: "src/index.ts"
      provides: "Entry point with bot.start() long polling"
      contains: "bot.start"
  key_links:
    - from: "src/telegram/handlers/message.ts"
      to: "src/ai/claude.ts"
      via: "calls generateResponse(text)"
      pattern: "generateResponse"
    - from: "src/telegram/handlers/message.ts"
      to: "src/telegram/bot.ts"
      via: "imports BotContext type"
      pattern: "BotContext"
    - from: "src/index.ts"
      to: "src/telegram/bot.ts"
      via: "imports bot and calls bot.start()"
      pattern: "bot\\.start"
    - from: "src/telegram/bot.ts"
      to: "src/telegram/handlers/message.ts"
      via: "registers message handler"
      pattern: 'bot\\.on\\("message:text"'
---

<objective>
Create the Claude AI client, wire the message handler into the bot, and update the entry point to use grammY long polling instead of the setInterval keepalive.

Purpose: Complete the end-to-end flow -- user sends Telegram message, Rachel shows typing, Claude generates response, Rachel replies.
Output: Fully working Telegram bot that responds to text messages with Claude-generated replies.
</objective>

<execution_context>
@/Users/lory/.claude/get-shit-done/workflows/execute-plan.md
@/Users/lory/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-telegram-integration-auth/02-RESEARCH.md
@.planning/phases/02-telegram-integration-auth/02-01-SUMMARY.md
@src/telegram/bot.ts
@src/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Claude AI client and message handler</name>
  <files>
    src/ai/claude.ts
    src/telegram/handlers/message.ts
    src/telegram/bot.ts
  </files>
  <action>
1. Create `src/ai/claude.ts` — Anthropic SDK client with generateResponse:
   ```typescript
   import Anthropic from "@anthropic-ai/sdk";
   import { env } from "../config/env.ts";

   const client = new Anthropic({ apiKey: env.ANTHROPIC_API_KEY });

   const SYSTEM_PROMPT = `You are Rachel, a personal AI assistant. You are helpful, concise, and friendly. You communicate via Telegram, so keep responses reasonably brief unless asked for detail.`;

   export async function generateResponse(userMessage: string): Promise<string> {
     const message = await client.messages.create({
       model: "claude-sonnet-4-5-20250929",
       max_tokens: 1024,
       system: SYSTEM_PROMPT,
       messages: [{ role: "user", content: userMessage }],
     });

     const textBlock = message.content.find((block) => block.type === "text");
     return textBlock?.text ?? "I'm sorry, I couldn't generate a response.";
   }
   ```
   Notes:
   - Uses basic `@anthropic-ai/sdk` (not Agent SDK) per Research recommendation. Agent SDK is for Phase 3 when tools are needed.
   - Uses `claude-sonnet-4-5-20250929` for Phase 2 (fast, cheap for basic responses). Model can be made configurable later.
   - Single-turn only (no conversation history). Phase 3 adds memory.
   - The Anthropic SDK has built-in retries for transient errors. Rate limits (429) still need to be caught by the caller.

2. Create `src/telegram/handlers/message.ts` — text message handler:
   ```typescript
   import type { BotContext } from "../bot.ts";
   import { generateResponse } from "../../ai/claude.ts";
   import { logger } from "../../lib/logger.ts";

   export async function handleMessage(ctx: BotContext): Promise<void> {
     const text = ctx.message?.text;
     if (!text) return;

     // Trigger typing indicator — autoChatAction plugin keeps it alive
     ctx.chatAction = "typing";

     try {
       const response = await generateResponse(text);
       await ctx.reply(response);
     } catch (error) {
       logger.error("Failed to generate response", {
         error: error instanceof Error ? error.message : String(error),
       });
       await ctx.reply("Sorry, I encountered an error. Please try again.");
     }
   }
   ```
   Notes:
   - Setting `ctx.chatAction = "typing"` activates the auto-chat-action plugin, which re-sends the typing indicator every 5 seconds until the handler completes (see Research pitfall 1).
   - try/catch wraps the Claude call so errors send a user-friendly message instead of crashing (see Research pitfall 6).

3. Update `src/telegram/bot.ts` — register the message handler. Add this import and handler registration:
   - Import: `import { handleMessage } from "./handlers/message.ts";`
   - Add `bot.on("message:text", handleMessage);` AFTER the /start command handler.
   - The handler registration order matters: /start command should be before the general message:text handler so that /start messages don't get passed to Claude.
  </action>
  <verify>
    Run `bunx tsc --noEmit` to check TypeScript compilation. Verify claude.ts exports generateResponse. Verify message.ts imports BotContext and generateResponse. Verify bot.ts registers handleMessage on "message:text".
  </verify>
  <done>
    Claude AI client created with generateResponse function. Message handler receives text, triggers typing indicator, calls Claude, replies with response. Handler registered on bot for message:text events.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update entry point to use grammY long polling</name>
  <files>
    src/index.ts
  </files>
  <action>
Replace the current `src/index.ts` content with the grammY long-polling entry point. The key changes:
- Remove the `setInterval` keepalive (bot.start() keeps the process alive)
- Import `bot` from `./telegram/bot.ts`
- Use `process.once` instead of `process.on` for signal handlers (see Research pitfall 5: prevents multiple shutdown attempts)
- Call `bot.stop()` in signal handlers instead of `process.exit(0)` (lets grammY clean up the polling loop)
- Use `await bot.start()` with onStart callback (Bun supports top-level await)

```typescript
/**
 * Rachel8 entry point.
 *
 * Starts the Telegram bot in long polling mode. The bot authenticates
 * the owner, shows typing indicators, and responds via Claude.
 */

import { bot } from "./telegram/bot.ts";
import { env } from "./config/env.ts";
import { logger } from "./lib/logger.ts";

// ── Startup ──────────────────────────────────────────────────────────────────

logger.info("Rachel8 starting...", { env: env.NODE_ENV });

logger.info("Configuration loaded", {
  sharedFolder: env.SHARED_FOLDER_PATH,
  logLevel: env.LOG_LEVEL,
});

// ── Graceful shutdown ────────────────────────────────────────────────────────
// Use process.once (not .on) to prevent multiple shutdown attempts

process.once("SIGTERM", () => bot.stop()); // systemd sends this on `systemctl stop`
process.once("SIGINT", () => bot.stop());  // Ctrl+C in terminal

// ── Start bot ────────────────────────────────────────────────────────────────
// Long polling keeps the process alive — replaces the old setInterval keepalive.
// bot.start() returns a Promise that resolves when bot.stop() is called.

await bot.start({
  onStart: () => logger.info("Rachel8 is running. Listening for messages..."),
});
```

The old shutdown() function and setInterval keepalive are removed entirely. The bot's long polling loop is the keepalive mechanism now.
  </action>
  <verify>
    Run `bun run src/index.ts` (will start the bot if .env is configured, or fail with env validation — both confirm syntax is correct). Verify no setInterval remains. Verify bot.stop() is called on SIGTERM/SIGINT. Verify process.once is used (not process.on).
  </verify>
  <done>
    Entry point uses grammY long polling via bot.start(). setInterval keepalive removed. Signal handlers call bot.stop() for clean shutdown. Process stays alive through polling loop.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify end-to-end Telegram messaging</name>
  <files>src/index.ts</files>
  <action>
Human verifies the complete Telegram bot with single-user auth, typing indicators, and Claude-powered responses.

Steps:
1. Ensure your `.env` has valid ANTHROPIC_API_KEY, TELEGRAM_BOT_TOKEN, and OWNER_TELEGRAM_USER_ID
2. Run `bun run start` (or `bun run dev` for watch mode)
3. Confirm logs show "Rachel8 is running. Listening for messages..."
4. Open Telegram and send /start to your bot — should reply "Hello! I'm Rachel, your personal AI assistant."
5. Send a text message like "What is 2+2?" — should see typing indicator, then receive a Claude-generated response
6. Verify typing indicator is visible while waiting for Claude's response
7. Press Ctrl+C — should shut down cleanly without errors
  </action>
  <verify>All 7 steps pass. Bot responds to messages, shows typing, and shuts down cleanly.</verify>
  <done>End-to-end Telegram messaging verified: auth works, typing shows, Claude responds, shutdown is clean.</done>
</task>

</tasks>

<verification>
1. `src/ai/claude.ts` creates Anthropic client, exports generateResponse using claude-sonnet-4-5-20250929
2. `src/telegram/handlers/message.ts` handles text messages, sets ctx.chatAction = "typing", calls generateResponse, replies
3. `src/telegram/bot.ts` registers handleMessage on "message:text"
4. `src/index.ts` uses bot.start() for long polling, process.once for signals, no setInterval
5. End-to-end: user sends message -> auth check -> typing indicator -> Claude response -> reply
6. Error handling: Claude API errors caught and user gets friendly error message
7. Graceful shutdown: SIGTERM/SIGINT -> bot.stop() -> clean exit
</verification>

<success_criteria>
- User can send a text message to Rachel on Telegram and receive a Claude-generated response
- Typing indicator shows while Claude processes the message
- Bot stays running and handles multiple messages without crashing
- Clean shutdown on SIGTERM/SIGINT (no hung processes)
- Errors in individual messages don't crash the bot
</success_criteria>

<output>
After completion, create `.planning/phases/02-telegram-integration-auth/02-02-SUMMARY.md`
</output>
